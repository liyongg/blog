{
  "hash": "64be60b227abce02fd0845b490feb2a8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Translating PDF content using an LLM\"\ndate: \"2024-04-03\"\ncategories: [text mining, deep learning, pytorch]\ndescription: '\"使用大语言模型翻译PDF内容\"'\ncode-fold: false\n---\n\nI have an extremely interesting and ambitious project that I am working on where I use React Native for the front end, and FastAPI as the backend.\nOne of the things I am considering to do is to include the use of a Large Language Model (LLM).\nLLMs have been the hype for quite some time now, and I thought it was time to put one to use, aside from the usual ChatGPT prompts that I run.\n\nToday I will use an LLM to translate content that we will extract from a PDF.\nNot very coincidentally it is a Dutch vocabulary list, which I want to translate to Mandarin Chinese.\n\n## Step 1: Finding a dataset\n\nThe very first relevant hit on Google brought me to a [NT2 Vocabulary List](https://www.nt2.nl/documenten/dm-derde_ronde-woordenlijst-lowres.pdf){target=\"_blank\"}.\nLet's save this PDF as `vocab.pdf`.\n\n## Step 2: Exploring the PDF using `pypdf`\n\n::: {#8c6fea36 .cell execution_count=1}\n``` {.python .cell-code}\nfrom pypdf import PdfReader\nreader = PdfReader(\"vocab.pdf\")\n```\n:::\n\n\nWe should at least check if it indeed has read correctly that `vocab.pdf` contains 36 pages\n\n::: {#462e9d0c .cell execution_count=2}\n``` {.python .cell-code}\nprint(f\"There are {len(reader.pages)} pages.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThere are 36 pages.\n```\n:::\n:::\n\n\nAlright, seems good!\n\n## Step 3: Extracting text\n\nThe `pages` value is a list of `PageObject` objects and each of these come with the `extract_text()` method.\nThe extracted content from the first page is the following:\n\n::: {#d941241b .cell execution_count=3}\n``` {.python .cell-code}\nfirst_page = reader.pages[0]\ntext_first_page = first_page.extract_text()\nprint(text_first_page)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1 Woordenlijst\nnr. cursief woord uit de tekst uitleg\nLes 1\n1 gevorderden mensen die al een tijd bezig zijn met een studie of vaardigheid en dus enige \nkennis en ervaring hebben; de gevorderde\n2 gemeenschappelijk met verschillende mensen dezelfde eigenschap of ruimte hebben\n3 raden to guess/erraten/deviner/tahmin etmek; raden-raadde-geraden \n4 afvragen jezelf een vraag stellen; afvragen-vroeg af-afgevraagd \n5 stelt … voor dat stelt niks voor = dat is helemaal niet belangrijk; voorstelde-stelde voor-\nvoorgesteld \n6 piepklein heel erg klein \n7 bomvol heel erg vol\n8 carpoolen met twee of meer mensen van één auto gebruikmaken om geld en het milieu te \nsparen; vooral van en naar je werk\n9 omelet (de) een mengsel van gebakken eieren; omeletten\n10 kebab gebakken vlees van een soort grill\n11 yoghurt zuur zuivelproduct gemaakt van melk, wordt meestal gegeten na het avondeten of bij het ontbijt\n12 chocola (de) bruin of wit snoep, gemaakt van cacao en suiker\n13 tof goed, leuk, aardig\n14 Hebreeuws (het) Hebreeuws = de Hebreeuwse taal (wordt gesproken in Israël)\n15 paradijs (het) een ideale, mooie en rustige plaats; de tuin waarin Adam en Eva woonden volgens de Bijbel en de Koran; de paradijzen \n16 schaken een spel spelen met 16 witte en 16 zwarte figuren op een bord met witte en zwarte vierkantjes; schaken-schaakte-geschaakt \n17 Perzisch (het) Perzisch = de Perzische taal = het Farsi (wordt gesproken in Iran)\n18 Indonesisch (het) Indonesisch = de Indonesische taal\n19 sowieso Duits: in elk geval\n20 terechtgekomen (toevallig) op een bepaalde plaats komen; terechtkomen-kwam terecht-terechtgekomen \n21 uitgeleend voor een tijdje aan iemand in gebruik gegeven; uitlenen-leende uit-uitgeleend \n22 verklap iets vertellen wat eigenlijk geheim moet blijven; verklappen-verklapte-verklapt \n23 discussiëren met argumenten bespreken; discussiëren-discussieerde-gediscussieerd\n24 verbazen het zal je verbazen = je zult wel verbaasd zijn. Dat verbaast me; verbazen-verbaasde-verbaasd\n25 cijfers getallen\n26 taalkundige linguïst, expert op het gebied van talen\n27 beschrijving (de) een verhaal vertellen over iets of iemand of over een gebeurtenis; beschrijvingen\n28 grafiek (de) figuur uit de statistiek met lijnen om cijfers beter te kunnen begrijpen; grafieken\n29 begrijpelijk goed te begrijpen\n30 daarover over dat onderwerp\n31 quitte quitte staan: gelijk staan; evenveel punten of evenveel hebben\n32 buurlanden de buren van een land; Duitsland en België zijn de buurlanden van Nederland; het buurland\n33 vanouds sinds lang geleden\n34 weggeeft hier: uitleent, de ene taal neemt woorden uit de andere taal over; weggeven-gaf weg-weggegeven \n35 aanbieding iets in de aanbieding hebben = iets goeds of waardevols wat je weg wilt geven of wilt verkopen\n36 emigreerden verhuisden naar een ander land; emigreren-emigreerde-geëmigreerd \n37 verhuisden van vaste plaats veranderen; verhuizen-verhuisde-verhuisd \n38 schets (de) tekening of ontwerp in grote lijnen; de schetsen\n39 schaats (de) schoen met ijzer eronder; om mee over het ijs te bewegen; schaatsen\n```\n:::\n:::\n\n\nIt is evident from scrolling through the PDF that it is quite well-structured: every word and its meaning start with some index.\nThis is reaffirmed with the string printed above.\nHowever, if we would use the string representation above, it would be incredibly tedious to find some algorithm that can help extract the most important information: the words and their corresponding meaning.\nOne naive way would be to define\n\n1.  the first word as the index;\n2.  the second word as the word in the vocabulary list;\n3.  the remaining words to be the corresponding meaning.\n\nBut this sucks.\nTo see that, let's first split the lines for this very long string and show the first 10 results.\n\n::: {#a7f7a66c .cell execution_count=4}\n``` {.python .cell-code}\nlines = text_first_page.splitlines()[:9]\nprint(\"\\n\".join(lines))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1 Woordenlijst\nnr. cursief woord uit de tekst uitleg\nLes 1\n1 gevorderden mensen die al een tijd bezig zijn met een studie of vaardigheid en dus enige \nkennis en ervaring hebben; de gevorderde\n2 gemeenschappelijk met verschillende mensen dezelfde eigenschap of ruimte hebben\n3 raden to guess/erraten/deviner/tahmin etmek; raden-raadde-geraden \n4 afvragen jezelf een vraag stellen; afvragen-vroeg af-afgevraagd \n5 stelt … voor dat stelt niks voor = dat is helemaal niet belangrijk; voorstelde-stelde voor-\n```\n:::\n:::\n\n\nBy using the naive way to divide the strings, the final line would give\n\n| Index | Word  | Meaning                                                                                  |\n|-------------------|-------------------|----------------------------------|\n| 5     | stelt | ... voor dat stelt niks voor = dat is helemaal niet belangrijk; voorstelde-stelde voor-' |\n\nBut the actual result should be\n\n| Index | Word           | Meaning                                                                         |\n|-------------------|-------------------|----------------------------------|\n| 5     | stelt ... voor | dat stelt niks voor = dat is helemaal niet belangrijk; voorstelde-stelde voor-' |\n\nNot great, so we have to find something else.\nThe same method has an argument `extraction_mode` which is set to `plain` by default.\nIf we use the `extract_text(extraction_mode=\"layout\")`, it allows us to apply a more rigid and robust method.\n\n::: {#4fc2ecfe .cell execution_count=5}\n``` {.python .cell-code}\ntext_first_page = first_page.extract_text(extraction_mode=\"layout\")\nlines = text_first_page.splitlines()[:9]\nprint(\"\\n\".join(lines))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nnr.                                                                                                           cursief woord uit de tekst                                                                                                           uitleg\n\n\n                                                              Les 1\n\n1                                                                                                                             gevorderden                                                                                                                                                                                                                                                                                   mensen die al een tijd bezig zijn met een studie of vaardigheid en dus enige\n                                                                                                                                                                                                                                                            kennis en ervaring hebben; de gevorderde\n2                                                                                                                             gemeenschappelijk                                                                                                                                                                                       met verschillende mensen dezelfde eigenschap of ruimte hebben\n3                                                                                                                             raden                                                                                                                                                                                                                                                                                                                                                                             to guess/erraten/deviner/tahmin etmek; raden-raadde-geraden\n```\n:::\n:::\n\n\nNow there are a lot more whitespace characters between each 'column'.\nA better - not necessarily the best - method would be to:\n\n1.  Filter the lines which are non-empty and start with a digit.\n2.  Aggregate the rows which belong to one word/meaning combination.\n3.  Split each line by at least three or more whitespace characters.\n4.  Define the first part as the word and define the remaining text as its meaning.\n5.  Create a Pandas DataFrame object for each page.\n6.  Concatenate all dataframes into one dataframe.\n\nLet's set up this pipeline.\n\n## Step 4: Set up a processing pipeline\n\nBelow is the `VocabExtractor.py` file containing all the necessary steps to create a Pandas DataFrame containing the entire vocabulary list.\nThe code should be self-explanatory, but we will highlight and explain some bits.\n\n::: {#9b4b91c4 .cell execution_count=6}\n``` {.python .cell-code}\nimport pandas as pd\nfrom pypdf import PdfReader\n\n\nclass VocabExtractor:\n    def __init__(self, pdf_path):\n        self.pdf_path = pdf_path\n\n    def validate_lines(self, lines):\n        return [line for line in lines if line and line[0].isdigit()]\n\n    def remove_overflow_lines(self, lines):  # <1>\n        res = [lines[0]]  # <1>\n        for current_item, next_item in zip(lines, lines[1:]):  # <1>\n            if next_item[0].isdigit():  # <1>\n                res.append(next_item)  # <1>\n            else:  # <1>\n                res[-1] += next_item  # <1>\n        return res  # <1>\n\n    def trim_index(self, lines):  # <2>\n        no_index_lines = [line[line.find(' '):] for line in lines]  # <2>\n        return [line.strip() for line in no_index_lines]  # <2>\n\n    def lines_to_df(self, lines):\n        split_lines = [line.split(\"  \") for line in lines]\n        words = [line[0] for line in split_lines]\n        meanings = [''.join(line[1:]).strip() for line in split_lines]\n        return pd.DataFrame.from_dict({\"Words\": words, \"Meanings\": meanings})\n\n    def pipeline_lines(self, text):\n        lines = text.splitlines()\n        page_lines = self.validate_lines(lines)\n        no_overflow_lines = self.remove_overflow_lines(page_lines)\n        no_index_lines = self.trim_index(no_overflow_lines)\n        return self.lines_to_df(no_index_lines)\n\n    def extract_from_pdf(self):  # <3>\n        reader = PdfReader(self.pdf_path)  # <3>\n        pages = reader.pages  # <3>\n\n        res = []  # <3>\n\n        for page in pages:  # <3>\n            page_text = page.extract_text(extraction_mode=\"layout\")  # <3>\n            res.append(self.pipeline_lines(page_text))  # <3>\n\n        df = pd.concat(res, ignore_index=True)  # <3>\n        df = df[df[\"Words\"] != \"Derde Ronde Nederlands voor buitenlanders\"].reset_index(\n            drop=True)  # <3>\n\n        return df  # <3>\n```\n:::\n\n\n1.  Initialise a list of which its only element is the first line of extracted text from the page. Then loop over the pairs of subsequent item pairs and check if the second element of the pair starts with a digit. If it does, then there is no overflow and the succeeding element is a valid new line of text which we append to the initial list. If it does not, then it means the line was overflown and we add this newline to the final element of the initial list.\n2.  For each line, extract the substring starting from the first 'word' following the first whitespace character. Effectively it removes the first word from each line, which should really be the index of the line.\n3.  Combine all methods defined above and loop through the pages to create a dataframe for each page. Finally concatenate all these dataframes and filter the lines which contain the 'word' \"Derde Ronde Nederlands voor buitenlanders\", as it is noise from the footer that appear on every even page.[^1]\n\n[^1]: It would also have been possible to crop the page before extracting the text, but to me it seemed like more work experimenting with the dimensions.\n\nNow we can run the following code:\n\n::: {#9da9be62 .cell execution_count=7}\n``` {.python .cell-code}\nvocab_extractor = VocabExtractor(\"vocab.pdf\")\ndf = vocab_extractor.extract_from_pdf()\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Meanings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gevorderden</td>\n      <td>mensen die al een tijd bezig zijn met een stud...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gemeenschappelijk</td>\n      <td>met verschillende mensen dezelfde eigenschap o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>raden</td>\n      <td>to guess/erraten/deviner/tahmin etmek; raden-r...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>afvragen</td>\n      <td>jezelf een vraag stellen; afvragen-vroeg af-af...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>stelt … voor</td>\n      <td>dat stelt niks voor = dat is helemaal niet bel...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1764</th>\n      <td>matchen</td>\n      <td>combineren, koppelen, bij elkaar brengen; matc...</td>\n    </tr>\n    <tr>\n      <th>1765</th>\n      <td>op goed geluk</td>\n      <td>willekeurig, blindelings, zonder planning</td>\n    </tr>\n    <tr>\n      <th>1766</th>\n      <td>presteren</td>\n      <td>prestaties leveren, werken; presteren-presteer...</td>\n    </tr>\n    <tr>\n      <th>1767</th>\n      <td>revalideren</td>\n      <td>weer leren bewegen na een ongeluk of operatie;...</td>\n    </tr>\n    <tr>\n      <th>1768</th>\n      <td>gerepareerd</td>\n      <td>in orde gemaakt; repareren-repareerde-gerepareerd</td>\n    </tr>\n  </tbody>\n</table>\n<p>1769 rows × 2 columns</p>\n</div>\n```\n:::\n:::\n\n\nThe PDF also contained 1769 words.\nLooks good to me!\n\n## Step 5: Trimming the extracted text for translation\n\nNow that we have our hands on the entirety of the PDF content, the only thing that remains to be done is to remove word redundancy.\nA quick scan through the PDF shows that (nearly) every noun shows a corresponding article (de/het) in the *Words* column and has its conjugations in the *Meanings* column.\nWe should remove these as\n\n1.  Dutch articles could potentially add noise to the context of the word and there are no direct translation for these articles;\n2.  Chinese Mandarin deals with conjugations differently: conjugations (usually) do not add relevant information to a word.\n\nThe pattern for the articles seems to be `(de/het)`.\nUsing regular expressions it should be `\\s\\s((de|het)\\)`.\nThe pattern for the conjugations seems to be `; words-words-words`.\nUsing regular expressions it would be a regex pattern of `;\\s*[\\w\\s]+-[\\w\\s]+-[\\w\\s]+`.\n\n::: {#cf709e40 .cell execution_count=8}\n``` {.python .cell-code}\ndf[\"Words_trimmed\"] = df[\"Words\"].replace(regex=r'\\s\\((de|het)\\)', value='')\ndf[\"Meanings_trimmed\"] = df[\"Meanings\"] \\\n    .replace(regex=r';\\s*[\\w\\s]+-[\\w\\s]+-[\\w\\s]+', value='') \\\n    .replace(regex=r'\\((de|het)\\)', value='') \\\n    .str.strip()\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Meanings</th>\n      <th>Words_trimmed</th>\n      <th>Meanings_trimmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gevorderden</td>\n      <td>mensen die al een tijd bezig zijn met een stud...</td>\n      <td>gevorderden</td>\n      <td>mensen die al een tijd bezig zijn met een stud...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gemeenschappelijk</td>\n      <td>met verschillende mensen dezelfde eigenschap o...</td>\n      <td>gemeenschappelijk</td>\n      <td>met verschillende mensen dezelfde eigenschap o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>raden</td>\n      <td>to guess/erraten/deviner/tahmin etmek; raden-r...</td>\n      <td>raden</td>\n      <td>to guess/erraten/deviner/tahmin etmek</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>afvragen</td>\n      <td>jezelf een vraag stellen; afvragen-vroeg af-af...</td>\n      <td>afvragen</td>\n      <td>jezelf een vraag stellen</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>stelt … voor</td>\n      <td>dat stelt niks voor = dat is helemaal niet bel...</td>\n      <td>stelt … voor</td>\n      <td>dat stelt niks voor = dat is helemaal niet bel...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1764</th>\n      <td>matchen</td>\n      <td>combineren, koppelen, bij elkaar brengen; matc...</td>\n      <td>matchen</td>\n      <td>combineren, koppelen, bij elkaar brengen</td>\n    </tr>\n    <tr>\n      <th>1765</th>\n      <td>op goed geluk</td>\n      <td>willekeurig, blindelings, zonder planning</td>\n      <td>op goed geluk</td>\n      <td>willekeurig, blindelings, zonder planning</td>\n    </tr>\n    <tr>\n      <th>1766</th>\n      <td>presteren</td>\n      <td>prestaties leveren, werken; presteren-presteer...</td>\n      <td>presteren</td>\n      <td>prestaties leveren, werken</td>\n    </tr>\n    <tr>\n      <th>1767</th>\n      <td>revalideren</td>\n      <td>weer leren bewegen na een ongeluk of operatie;...</td>\n      <td>revalideren</td>\n      <td>weer leren bewegen na een ongeluk of operatie;...</td>\n    </tr>\n    <tr>\n      <th>1768</th>\n      <td>gerepareerd</td>\n      <td>in orde gemaakt; repareren-repareerde-gerepareerd</td>\n      <td>gerepareerd</td>\n      <td>in orde gemaakt</td>\n    </tr>\n  </tbody>\n</table>\n<p>1769 rows × 4 columns</p>\n</div>\n```\n:::\n:::\n\n\nAlright!\nLet's make lists of these words and their meanings to serve as input for an LLM.\n\n::: {#6b603ff7 .cell execution_count=9}\n``` {.python .cell-code}\nwords = df[\"Words_trimmed\"].tolist()\nmeanings = df[\"Meanings_trimmed\"].tolist()\n```\n:::\n\n\n## Step 6: Incorporating an LLM\n\nThe scope of this post is not to train or finetune an LLM ourselves, which means we can use any suitable model on the [Hugging Face](https://huggingface.co/) platform.\nWhen navigating to the *Models* page on Hugging Face, we filter the LLMs by selecting *Translation* as NLP task and *Dutch* and *Chinese* as languages.\nThe first LLM sorted by *Trending* is [facebook/nllb-200-distilled-600M](https://huggingface.co/facebook/nllb-200-distilled-600M) and we will try it out.\n\nThe modal `Use in Transformers` is incredibly useful as it displays a copy-able code snippet.\nThe only thing that is missing is the explicit specification of using an NVIDIA GPU, as I am running the code using a NVIDIA GTX 1080 that has 8GB of VRAM.\n\n::: {#d147e98d .cell execution_count=10}\n``` {.python .cell-code}\nfrom transformers import pipeline\n\npipe = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\", device=\"cuda:0\")\n```\n:::\n\n\nLet's now define a `translate` function that translates a list of tokens.\nSomething to take into account is to add the specifications of the `src_lang` (source language) and `tgt_lang` (target language) in the pipeline, which we we add as optional arguments in the function.\nTo get a better idea of how long it takes for the translations to finish using 4GB (default) of the GPU, we can return a dictionary with the translations\n\n::: {#82264111 .cell execution_count=11}\n``` {.python .cell-code}\nimport time\n\ndef translate(tokens, src_lang=\"nld_Latn\", tgt_lang=\"zho_Hans\"):\n    start = time.time()\n    translation = pipe(tokens, src_lang=src_lang, tgt_lang=tgt_lang)\n    end = time.time()\n    return {\"translation\": translation, \"time\": end-start}\n```\n:::\n\n\nLet's test the function by translating the English title of this post into Mandarin Chinese.\n\n::: {#a0fdc65d .cell execution_count=12}\n``` {.python .cell-code}\ntitle = translate(\"Translating PDF content using a Large Language Model\", src_lang=\"eng_Latn\")\ntitle[\"translation\"][0][\"translation_text\"]\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n'使用大语言模型翻译PDF内容'\n```\n:::\n:::\n\n\nLooks decent[^2] to me!\n\n[^2]: Other translators could return \"大型语言\" instead of \"大语言\" and the former is indeed more accurate.\n\n## Step 7: Translating a batch of words\n\nThe `words` and `meanings` variables are ready to be plugged into the `translate` function.\nWe will add the translations to the existing `df` and write the dataframe to a csv file.\n\n::: {#c2f526fe .cell execution_count=13}\n``` {.python .cell-code}\ntranslations_words_nllb = translate(words)\ntranslations_meanings_nllb = translate(meanings)\n\ndf[\"CN_Words_NLLB\"] = [item[\"translation_text\"] for item in translations_words_nllb[\"translation\"]]\ndf[\"CN_Meanings_NLLB\"] = [item[\"translation_text\"] for item in translations_meanings_nllb[\"translation\"]]\n\ndf.to_csv(\"vocab.csv\", sep=\";\", index=False, encoding=\"utf-8-sig\")\ndf\n```\n:::\n\n\n::: {#330e4e8f .cell execution_count=14}\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Meanings</th>\n      <th>Words_trimmed</th>\n      <th>Meanings_trimmed</th>\n      <th>CN_Words_NLLB</th>\n      <th>CN_Meanings_NLLB</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gevorderden</td>\n      <td>mensen die al een tijd bezig zijn met een stud...</td>\n      <td>gevorderden</td>\n      <td>mensen die al een tijd bezig zijn met een stud...</td>\n      <td>领先者</td>\n      <td>那些已经在学习或技能中工作过的,</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gemeenschappelijk</td>\n      <td>met verschillende mensen dezelfde eigenschap o...</td>\n      <td>gemeenschappelijk</td>\n      <td>met verschillende mensen dezelfde eigenschap o...</td>\n      <td>共同</td>\n      <td>具有不同的人的特性或空间</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>raden</td>\n      <td>to guess/erraten/deviner/tahmin etmek; raden-r...</td>\n      <td>raden</td>\n      <td>to guess/erraten/deviner/tahmin etmek</td>\n      <td>推</td>\n      <td>为了猜测/猜测/猜测/推测</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>afvragen</td>\n      <td>jezelf een vraag stellen; afvragen-vroeg af-af...</td>\n      <td>afvragen</td>\n      <td>jezelf een vraag stellen</td>\n      <td>问问</td>\n      <td>问自己一个问题</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>stelt … voor</td>\n      <td>dat stelt niks voor = dat is helemaal niet bel...</td>\n      <td>stelt … voor</td>\n      <td>dat stelt niks voor = dat is helemaal niet bel...</td>\n      <td>代表</td>\n      <td>没有什么意思.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1764</th>\n      <td>matchen</td>\n      <td>combineren, koppelen, bij elkaar brengen; matc...</td>\n      <td>matchen</td>\n      <td>combineren, koppelen, bij elkaar brengen</td>\n      <td>匹配</td>\n      <td>结合,结合,组合</td>\n    </tr>\n    <tr>\n      <th>1765</th>\n      <td>op goed geluk</td>\n      <td>willekeurig, blindelings, zonder planning</td>\n      <td>op goed geluk</td>\n      <td>willekeurig, blindelings, zonder planning</td>\n      <td>祝你好运</td>\n      <td>随机,盲目,没有计划</td>\n    </tr>\n    <tr>\n      <th>1766</th>\n      <td>presteren</td>\n      <td>prestaties leveren, werken; presteren-presteer...</td>\n      <td>presteren</td>\n      <td>prestaties leveren, werken</td>\n      <td>能做到</td>\n      <td>提供工作,工作</td>\n    </tr>\n    <tr>\n      <th>1767</th>\n      <td>revalideren</td>\n      <td>weer leren bewegen na een ongeluk of operatie;...</td>\n      <td>revalideren</td>\n      <td>weer leren bewegen na een ongeluk of operatie;...</td>\n      <td>恢复</td>\n      <td>事故或手术后重新学习运动;</td>\n    </tr>\n    <tr>\n      <th>1768</th>\n      <td>gerepareerd</td>\n      <td>in orde gemaakt; repareren-repareerde-gerepareerd</td>\n      <td>gerepareerd</td>\n      <td>in orde gemaakt</td>\n      <td>修复</td>\n      <td>整好了</td>\n    </tr>\n  </tbody>\n</table>\n<p>1769 rows × 6 columns</p>\n</div>\n```\n:::\n:::\n\n\nDownload the [vocab.csv](vocab.csv) if you are interested or would like to work with this dataset!\n\n## Step 8: Evaluating the results\n\nMy Mandarin is nowhere near native level, but when quickly skimming the dataset it is evident that the direct translation of some words are not correct.\nIt uses the character 子 in those occasions, which has various meaning and uses in different contexts.\nAlso, the meanings are sometimes oddly translated, as for some words the corresponding meaning is really not that useful.\n\nIn general, the direct translations of the words could serve as a potential starting point for my upcoming project.\nHowever, a better starting point would probably to find a Dutch-Chinese vocabulary list.\nAn LLM could then be used to explain the words.\n\nThat's all for today, thanks for reading!\n\n",
    "supporting": [
      "index_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}